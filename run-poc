#!/bin/bash
# Quick POC runner - uses Gemini Flash for complex, tiny local for simple
#
# Usage:
#   ./run-poc                           # Run with default test-poc project
#   ./run-poc /path/to/project          # Run with custom project
#   ./run-poc /path/to/project tasks.md # Run with custom project and tasks
#
# Requirements:
#   - GEMINI_API_KEY environment variable set
#   - Ollama installed and running
#   - qwen2.5-coder:1.5b model (will be pulled if missing)

SCRIPT_DIR="$(cd "$(dirname "$0")" && pwd)"

echo "=============================================="
echo "  Autobot POC - Hybrid Mode"
echo "=============================================="
echo "  Local:  qwen2.5-coder:1.5b (your GPU, ~1.5GB VRAM)"
echo "  Cloud:  gemini-2.5-flash (API, ~\$0.10-0.30/M tokens)"
echo ""
echo "  Strategy:"
echo "    - Tasks 1-3: Gemini Flash (foundation)"
echo "    - Complex tasks: Gemini Flash (architecture)"
echo "    - Simple tasks: Local Ollama (polish/tweaks)"
echo "=============================================="
echo ""

# Check for API key
if [ -z "$GEMINI_API_KEY" ]; then
    echo "Warning: GEMINI_API_KEY not set"
    echo ""
    echo "To use Gemini for complex tasks, set your API key:"
    echo "  export GEMINI_API_KEY='your-key-here'"
    echo ""
    echo "Get a key at: https://aistudio.google.com/app/apikey"
    echo ""
    read -p "Continue with local-only mode? [y/N] " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        exit 1
    fi
    echo "Running in local-only mode (no hybrid)..."
    HYBRID_FLAG=""
else
    echo "Gemini API key found"
    HYBRID_FLAG="--hybrid"
fi

# Check if Ollama is running
if ! command -v ollama &> /dev/null; then
    echo "Error: Ollama not found. Please install it first:"
    echo "  curl -fsSL https://ollama.com/install.sh | sh"
    exit 1
fi

# Pull local model if needed (suppress output unless there's an error)
echo "Checking local model (qwen2.5-coder:1.5b)..."
if ! ollama list | grep -q "qwen2.5-coder:1.5b"; then
    echo "Pulling qwen2.5-coder:1.5b (~1GB download)..."
    ollama pull qwen2.5-coder:1.5b
    if [ $? -ne 0 ]; then
        echo "Error: Failed to pull model"
        exit 1
    fi
fi
echo "Local model ready"
echo ""

# Determine project and tasks paths
PROJECT_PATH="${1:-$SCRIPT_DIR/projects/test-poc}"
TASKS_PATH="${2:-$PROJECT_PATH/tasks.md}"

# Validate paths
if [ ! -d "$PROJECT_PATH" ] && [ ! -f "$TASKS_PATH" ]; then
    echo "Creating project directory: $PROJECT_PATH"
    mkdir -p "$PROJECT_PATH"
fi

if [ ! -f "$TASKS_PATH" ]; then
    echo "Error: Tasks file not found: $TASKS_PATH"
    echo ""
    echo "Create a tasks.md file with your tasks, e.g.:"
    echo ""
    echo "  ## Task 1: Setup project"
    echo "  Create the basic project structure..."
    echo ""
    echo "  ## Task 2: Add feature"
    echo "  Implement the main feature..."
    exit 1
fi

echo "Project: $PROJECT_PATH"
echo "Tasks:   $TASKS_PATH"
echo ""

# Run overnight.py with hybrid mode
echo "Starting Autobot..."
echo "=============================================="
echo ""

exec python3 "$SCRIPT_DIR/overnight.py" \
    --project "$PROJECT_PATH" \
    --tasks "$TASKS_PATH" \
    --model "ollama/qwen2.5-coder:1.5b" \
    $HYBRID_FLAG \
    --timeout 600 \
    "${@:3}"
